{"cells":[{"cell_type":"markdown","metadata":{"_uuid":"a6013e8a57b2f9043ab25e274e565868a00f76cd"},"source":[]},{"cell_type":"markdown","metadata":{"_uuid":"544dae70888022a55ba3e1addf56f605024720db"},"source":["**Introduction**\n","This kernel was made to formalize reviews for the prescripted medicine and considers how such reviews might develop in the future. Medication feedback made by customers can help them find the most cost-effectiveness drug and for pharmacists there is good evidence that medication review improves process outcomes of prescribing and spot out specific problems early on. \n","We will use MAE for this because we don't need positive errors to cancel out negative ones or to give a relatively high weight to large errors."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["import os, pickle\n","import re, gc\n","import keras\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import warnings\n","from matplotlib import pyplot as plt\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.model_selection import KFold\n","from keras.preprocessing import text, sequence\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n","from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n","from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate\n","from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\n","from keras.optimizers import Adam\n","from keras.models import Model\n","from keras import backend as K\n","from keras.engine.topology import Layer\n","from keras import initializers, regularizers, constraints, optimizers, layers"]},{"cell_type":"markdown","metadata":{"_uuid":"f780ff1ddad972203585b35104b3dc98e550c03a","trusted":true},"source":["Letâ€™s prepare the data.\n","\n","Tip: you can use \"config style\" for code reusability and faster experiments"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"c15735ced18a30224e390cdabc5ec6ac085b1043","trusted":true},"outputs":[],"source":["conf = {\n","    \"kaggle\" : True,\n","    \"embedding_file\" : '../input/glove840b300dtxt/glove.840B.300d.txt',\n","    \"embedding_pickle\" : '/data/glove.840B.300d/glove.840B.300d.pickle',\n","    \"train_path\" : \"../input/kuc-hackathon-winter-2018/drugsComTrain_raw.csv\",\n","    \"test_path\" : \"../input/kuc-hackathon-winter-2018/drugsComTest_raw.csv\",\n","    \n","    \n","    \"max_features\" : 30000,\n","    \"maxlen\" : 100,\n","    \"embed_size\" : 300,\n","    \n","    \n","    \"batch_size\":3000,\n","    \"epochs\":500,\n","    \"n_splits\":10,\n","    \"random_state\":0\n","}\n","\n","model_conf = {\n","    \"SpDr\": 0.2,\n","    \"GRU_Units\":128,\n","    \"Conv_Units\":128,\n","    \"conv_kernel\":1,\n","    \"Dense1_Unit\":128,\n","    \"Dr1\":0.2,\n","    \"Dense2_Unit\":128,\n","    \"Dr2\": 0.2,\n","    \n","    \n","    \"lr\" : 1e-4,\n","    \"loss\" : 'mean_absolute_error',\n","    \"metrics\": ['mae']#list\n","}"]},{"cell_type":"markdown","metadata":{"_uuid":"77e6cce6b2bbcbfa7db6df2aa7cfcc0118aca528"},"source":["The first thing we must check is the distribution of rating.This graph is bimodal distribution due to the reasons why customers write review in the first place."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"3f6b4bd296a25b1d5bf223e0427a8cd3113a5530","trusted":true},"outputs":[],"source":["d_train = pd.read_csv(conf[\"train_path\"])\n","d_test = pd.read_csv(conf[\"test_path\"])\n","\n","plt.figure(figsize=(8,8))\n","sns.distplot(d_train['rating'])\n","\n","plt.xlabel('Rating')\n","plt.ylabel('Dist')\n","plt.title(\"Distribution of rating\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"_uuid":"9f9552db3ce83d8f9d5418689e6c1e97b1872aaf"},"source":["We examine the total amount of rewiews made per year. Growth from year 2015 and later have reasons (maybe social) unimportant for the current goal"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"ee7c22f026b0d6ac28f0746e62f18ec5f204bf62","trusted":true},"outputs":[],"source":["d_train['year'] = pd.to_datetime(d_train['date'], errors='coerce')\n","cnt = d_train['year'].dt.year.value_counts()\n","cnt = cnt.sort_index()\n","plt.figure(figsize=(9,6))\n","sns.barplot(cnt.index, cnt.values,color='blue',alpha=0.4)\n","plt.xticks(rotation='vertical')\n","plt.xlabel('Year', fontsize=12)\n","plt.ylabel('Count', fontsize=12)\n","plt.title(\"Reviews per year\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"_uuid":"a129ff9aaa9ee25b3512d83db54a0c74bfc6859a"},"source":["We examine the total amount of rewiews made per month. The graph is constant so it isn't really important."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"1004c7d501e835abfb2af0f880cd6c68039c6598","trusted":true},"outputs":[],"source":["d_train['month'] = pd.to_datetime(d_train['date'], errors='coerce')\n","cnt = d_train['month'].dt.month.value_counts()\n","cnt = cnt.sort_index()\n","plt.figure(figsize=(9,6))\n","sns.barplot(cnt.index, cnt.values,color='blue',alpha=0.4)\n","plt.xticks(rotation='vertical')\n","plt.xlabel('Month', fontsize=12)\n","plt.ylabel('Count', fontsize=12)\n","plt.title(\"Reviews per month\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"_uuid":"b49410c628f1b6d76ba60870d480ff015c5877fe"},"source":["We examine the total amount of rewiews made per day. As the previous one, the graph is constant ."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"76208a9b2e715632a66ad9d23a088e350bc23451","trusted":true},"outputs":[],"source":["d_train['day'] = pd.to_datetime(d_train['date'], errors='coerce')\n","cnt = d_train['day'].dt.day.value_counts()\n","cnt = cnt.sort_index()\n","plt.figure(figsize=(9,6))\n","sns.barplot(cnt.index, cnt.values,color='blue',alpha=0.4)\n","plt.xticks(rotation='vertical')\n","plt.xlabel('Day', fontsize=12)\n","plt.ylabel('Count', fontsize=12)\n","plt.title(\"Reviews per day\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"_uuid":"3ff3caf97d124cec78d0d6a2cd551a917c493e6a"},"source":["Top 10 popular drugs. Birth control and antidepressants are the most common drugs to see on top"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"c1625312ec2122dc19a8614a1ab2748906a63f44","trusted":true},"outputs":[],"source":["drug = d_train['drugName'].value_counts()\n","\n","plt.figure(figsize=(20,6))\n","\n","sns.barplot(drug[:15].index, drug[:15],color='blue',alpha=0.4)\n","\n","plt.xlabel('Name of drug', fontsize=12)\n","plt.ylabel('Count', fontsize=12)\n","plt.title(\"Top 10 popular drugs\")\n","plt.xticks(rotation=90)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"_uuid":"4e46556e3ce7a21bd3c1ce98033f3cad3f7a07fd"},"source":["Number of users who found review useful. Gamma distribution it is"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"ce91734f33e108a831311a46dbb0e88a7ac8f934","trusted":true},"outputs":[],"source":["plt.figure(figsize=(16,8))\n","\n","sns.distplot(d_train['usefulCount'].value_counts())\n","\n","\n","plt.xlabel('Number of users who found review useful')\n","plt.ylabel('Dist')\n","plt.title(\"Distribution of usefulCount\")\n","\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"_uuid":"6f4418fd5b4c840cdbddc9ef98b96749c888ecf6"},"source":["Correlation between rating and users who found review useful. Positive linear correlation\n","\n","Acording to this we decided to use **only** text data for preventing major **data leak** and, you know, be more usefull in real world application"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"a690e358203a0d317e69ca620a042da3223d7f36","trusted":true},"outputs":[],"source":["plt.figure(figsize=(8,6))\n","\n","sns.lineplot(x='rating',y='usefulCount',data=d_train)"]},{"cell_type":"markdown","metadata":{"_uuid":"5eb953bbb06b6c0a0887adeea1504326110f867d"},"source":["Test the distribution of ratings in train and test dataset. Graphs are similar, the data was choosen correctly "]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"35d9efee1af1f16d412fdb7597bbd832133bcde6","trusted":true},"outputs":[],"source":["plt.figure(figsize=(9,9))\n","\n","sns.distplot(d_train['rating'])\n","sns.distplot(d_test['rating'],color='violet')\n","\n","plt.xlabel('Rating')\n","plt.ylabel('Dist')\n","plt.title(\"Distribution of rating (train and test)\")\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"_uuid":"d4613b408dab3e42c37b3b222b8920d04ab9616c"},"source":["For easier predictions we divide ratings by 10"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"bff077dc2294c3ffd6d8e8c63c50c56468438c36","trusted":true},"outputs":[],"source":["train = pd.read_csv(conf[\"train_path\"])\n","test = pd.read_csv(conf[\"test_path\"])\n","\n","X_train = train[\"review\"]\n","y_train = train[\"rating\"].values / 10\n","\n","X_test = test[\"review\"]\n","sample_pred = np.zeros_like(test[\"rating\"], dtype=np.float32)\n","\n","tokenizer = text.Tokenizer(num_words=conf[\"max_features\"])\n","tokenizer.fit_on_texts(list(X_train) + list(X_test))\n","X_train = tokenizer.texts_to_sequences(X_train)\n","X_test = tokenizer.texts_to_sequences(X_test)\n","x_train = sequence.pad_sequences(X_train, maxlen=conf[\"maxlen\"])\n","x_test = sequence.pad_sequences(X_test, maxlen=conf[\"maxlen\"])"]},{"cell_type":"markdown","metadata":{"_uuid":"0178c0cc89b0cba736537af9d34ba400af4cd550","trusted":true},"source":["Split reviews by words  and do embedding matrix\n","\n","We choose Glove embedding, cause we earned best scores here"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"b3a87eb30448c4e0a506ea35a7f0fa039c2f738a","trusted":true},"outputs":[],"source":["if conf[\"kaggle\"]: #tip: cause of config code style you can use same code of local experiments & for kaggle submission\n","    def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n","    embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(conf[\"embedding_file\"],encoding=\"UTF-8\"))\n","else:\n","    with open(conf[\"embedding_pickle\"], 'rb') as handle: #if you dont want to wait 6-9 minuts you can pickle your dict once\n","        embeddings_index = pickle.load(handle) # and just unpickle next, it may take near 10-20 seconds\n","    \n","word_index = tokenizer.word_index\n","nb_words = min(conf[\"max_features\"], len(word_index))\n","embedding_matrix = np.zeros((nb_words, conf[\"embed_size\"]))\n","for word, i in word_index.items():\n","    if i >= conf[\"max_features\"]: continue\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n","    \n","conf[\"embedding_matrix\"] = embedding_matrix\n","\n","del embeddings_index\n","gc.collect()"]},{"cell_type":"markdown","metadata":{"_uuid":"98cf76021eec5055d0f7cf97a84e5f36cbd82718"},"source":["Writing attention mechanism.\n","\n","Because word processing task can be described as sequence processing task we make two layered lstm with Attention to prevent overfitting and data augmentation\n","\n","Actually stolen from: https://www.kaggle.com/qqgeogor/keras-lstm-attention-glove840b-lb-0-043"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"a5b3e9bd5af07de118f803ce51cd7aab18cb0734","trusted":true},"outputs":[],"source":["class Attention(Layer):\n","    def __init__(self, step_dim,\n","                 W_regularizer=None, b_regularizer=None,\n","                 W_constraint=None, b_constraint=None,\n","                 bias=True, **kwargs):\n","        self.supports_masking = True\n","        self.init = initializers.get('glorot_uniform')\n","\n","        self.W_regularizer = regularizers.get(W_regularizer)\n","        self.b_regularizer = regularizers.get(b_regularizer)\n","\n","        self.W_constraint = constraints.get(W_constraint)\n","        self.b_constraint = constraints.get(b_constraint)\n","\n","        self.bias = bias\n","        self.step_dim = step_dim\n","        self.features_dim = 0\n","        super(Attention, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        assert len(input_shape) == 3\n","\n","        self.W = self.add_weight((input_shape[-1],),\n","                                 initializer=self.init,\n","                                 name='{}_W'.format(self.name),\n","                                 regularizer=self.W_regularizer,\n","                                 constraint=self.W_constraint)\n","        self.features_dim = input_shape[-1]\n","\n","        if self.bias:\n","            self.b = self.add_weight((input_shape[1],),\n","                                     initializer='zero',\n","                                     name='{}_b'.format(self.name),\n","                                     regularizer=self.b_regularizer,\n","                                     constraint=self.b_constraint)\n","        else:\n","            self.b = None\n","\n","        self.built = True\n","\n","    def compute_mask(self, input, input_mask=None):\n","        return None\n","\n","    def call(self, x, mask=None):\n","        features_dim = self.features_dim\n","        step_dim = self.step_dim\n","\n","        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n","                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n","\n","        if self.bias:\n","            eij += self.b\n","\n","        eij = K.tanh(eij)\n","\n","        a = K.exp(eij)\n","\n","        if mask is not None:\n","            a *= K.cast(mask, K.floatx())\n","\n","        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n","\n","        a = K.expand_dims(a)\n","        weighted_input = x * a\n","        return K.sum(weighted_input, axis=1)\n","\n","    \n","    def compute_output_shape(self, input_shape):\n","        return input_shape[0],  self.features_dim\n"]},{"cell_type":"markdown","metadata":{"_uuid":"bcde53daadee4d0b6641d013ee8217daec3ca6ad"},"source":["We chose to combine 2 kinds of models: \n","\n","First is really complicated 2 layer LSTM model with Attention layer for increasing information \"capability\", its model focusing on catching sequence information. Also checkout\n","\n","this: https://arxiv.org/pdf/1709.00893v1.pdf\n","\n","and this: https://www.kaggle.com/qqgeogor/keras-lstm-attention-glove840b-lb-0-043  we changed alot, but base arcitecture was took"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"862951ce7e81e9a9ed42752262b46651b89db43b","trusted":true},"outputs":[],"source":["def model_lstm_atten(main_conf: dict, model_conf:dict):\n","    inp = Input(shape=(main_conf[\"maxlen\"], ))\n","    x = Embedding(main_conf[\"max_features\"], main_conf[\"embed_size\"], weights=[main_conf[\"embedding_matrix\"]],trainable = False)(inp)\n","    x = Bidirectional(CuDNNLSTM(model_conf[\"LSTM_first_layer_units\"], return_sequences=True))(x)\n","    x = Bidirectional(CuDNNLSTM(model_conf[\"LSTM_second_layer_units\"], return_sequences=True))(x)\n","    x = Attention(main_conf[\"maxlen\"])(x)\n","    x = Dense(64, activation=\"relu\")(x)\n","    x = Dense(1, activation=\"relu\")(x)\n","    model = Model(inputs=inp, outputs=x)\n","    model.compile(loss=model_conf[\"loss\"],optimizer=Adam(lr=model_conf[\"lr\"]),metrics=model_conf[\"metrics\"])\n","    \n","    return model"]},{"cell_type":"markdown","metadata":{"_uuid":"46b12f6f12974b68206e107791005ceae5a1c5c3"},"source":["Second is old but still attrective GRU->CNN->Dense, was used by us in Toxic Classification Challange and it gave us bronze medal:)\n","\n","This model is more about catchaning structure of sentences. Also checkout this:\n","\n","I havent find original paper(cause it wasnt on arxiv(facepalm)) but you can look here: https://arxiv.org/pdf/1806.11316v1.pdf"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"0e9915f16c491c71985aba4df2b09eb279ae196b","trusted":true},"outputs":[],"source":["def get_toxic_model(main_conf: dict, model_conf:dict):\n","    sequence_input = Input(shape=(main_conf[\"maxlen\"], ))\n","    x = Embedding(main_conf[\"max_features\"], main_conf[\"embed_size\"], weights=[main_conf[\"embedding_matrix\"]],trainable = False)(sequence_input)\n","    x = SpatialDropout1D(model_conf[\"SpDr\"])(x)\n","    x = Bidirectional(CuDNNGRU(model_conf[\"GRU_Units\"], return_sequences=True))(x)\n","    x = Conv1D(model_conf[\"Conv_Units\"], kernel_size = model_conf[\"conv_kernel\"], padding = \"valid\", kernel_initializer = \"glorot_uniform\")(x)\n","    avg_pool = GlobalAveragePooling1D()(x)\n","    max_pool = GlobalMaxPooling1D()(x)\n","    x = concatenate([avg_pool, max_pool])\n","    x = Dense(model_conf[\"Dense1_Unit\"], activation='relu')(x)\n","    x = Dropout(model_conf[\"Dr1\"])(x)\n","    x = Dense(model_conf[\"Dense2_Unit\"], activation='relu')(x)\n","    x = Dropout(model_conf[\"Dr2\"])(x)\n","    preds = Dense(1, activation=\"sigmoid\")(x)\n","    model = Model(sequence_input, preds)\n","    model.compile(loss=model_conf[\"loss\"],optimizer=Adam(lr=model_conf[\"lr\"]),metrics=model_conf[\"metrics\"])\n","    return model"]},{"cell_type":"markdown","metadata":{"_uuid":"acaae8466a9aa6a714ea32b9d71cff2dbef39dd1"},"source":["Using out of fold predictions and  blending them"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"f4f7e20d9628cfa9c01ae56bd3740e1965583f51","trusted":true},"outputs":[],"source":["kf = KFold(n_splits=conf[\"n_splits\"], shuffle=True, random_state=conf[\"random_state\"])\n","cnt = 0\n","model_conf[\"LSTM_first_layer_units\"] = 128\n","model_conf[\"LSTM_second_layer_units\"] = 64\n","\n","for train_index, test_index in kf.split(x_train, y_train):\n","    model = model_lstm_atten(conf, model_conf)\n","    es = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')\n","\n","    hist = model.fit(x_train[train_index], y_train[train_index], batch_size=conf[\"batch_size\"], epochs=conf[\"epochs\"], \n","                     validation_data=(x_train[test_index], y_train[test_index]),callbacks=[es])\n","    model.save(f\"model_lstm_atten_cv_{cnt}.keras\")\n","    \n","    sample_pred +=  model.predict(x_test, conf[\"batch_size\"]*2).reshape(-1)\n","    cnt+=1"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"59908c2870679b057aad8aa27c43ead3559f3d91","trusted":true},"outputs":[],"source":["kf = KFold(n_splits=conf[\"n_splits\"], shuffle=True, random_state=conf[\"random_state\"])\n","cnt = 0\n","\n","for train_index, test_index in kf.split(x_train, y_train):\n","    model = get_toxic_model(conf, model_conf)\n","    es = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')\n","\n","    hist = model.fit(x_train[train_index], y_train[train_index], batch_size=conf[\"batch_size\"], epochs=conf[\"epochs\"], \n","                     validation_data=(x_train[test_index], y_train[test_index]),callbacks=[es])\n","    model.save(f\"model_gru_cnn_{cnt}.keras\")\n","    \n","    sample_pred +=  model.predict(x_test, conf[\"batch_size\"]*2).reshape(-1)\n","    cnt+=1"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"b34e64e4c59317507134aad418d2a996c570bc2b","trusted":true},"outputs":[],"source":["print(mean_absolute_error(test[\"rating\"], 10 * sample_pred/ conf[\"n_splits\"]/2))\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}
